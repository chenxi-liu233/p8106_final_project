---
title: "Final Project"
output:
  html_document
--- 

```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(tidyverse)
library(visdat)
library(corrplot)
library(RColorBrewer)
library(reshape2)
library(caret)
library(glmnet)
library(mlbench)
library(pROC)
library(pdp)
library(vip)
library(AppliedPredictiveModeling)
library(miscset)
library(corrplot)
library(rpart.plot) 
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
theme1 <- transparentTheme(trans = .4)
trellis.par.set(theme1)
```


## Data Prerview
Import data.
```{r}
heart_ori = read_csv("framingham.csv") %>% 
  janitor::clean_names() 

vis_miss(heart_ori)
```

Check correlation to see if we can impute glucose as it missing a lot.
```{r}
corrplot(cor(model.matrix(ten_year_chd~., heart_ori)[,-1]), 
         type="upper", order="hclust",
         tl.col = "black", tl.srt = 45,
         col=brewer.pal(n=8, name="RdYlBu"))
```

Impute the glucose with diabetes.
```{r}
temp = heart_ori %>% select(glucose, diabetes)
bag_impute = preProcess(temp, method = "bagImpute")
temp_imputed = predict(bag_impute, temp)

vis_miss(temp_imputed)
heart_ori$glucose = temp_imputed$glucose
vis_miss(heart_ori)
```

Format variables and omit observations with missing values (0.4%).
```{r}
heart = heart_ori %>% 
        na.omit() %>% 
        mutate(ten_year_chd=recode(ten_year_chd,'1'="yes",'0'="no")) %>% 
        mutate_at(c(1,4,6,7,8,9,16), funs(factor(.))) 
head(heart)
```

Check and preview basic statistics of the processed data.
```{r}
vis_miss(heart)
skimr::skim_without_charts(heart)
```

```{r}
featurePlot(x = heart[, c(2,3,5,10,11,12,13,14,15)],
            y = heart$ten_year_chd, scales = list(x=list(relation="free"),
                                               y=list(relation="free")),
            plot = "density",
            pch = "|",
            auto.key = list(columns = 4))
```

Visualization of variables
```{r}
heart_eda = heart %>%
  # mutate dummy variable for visualization labels
  mutate(male = ifelse(male == 1, "Yes", "No"),
         current_smoker = ifelse(current_smoker == 1, "Yes", "No"),
         bp_meds = ifelse(bp_meds == 1, "Yes", "No"),
         prevalent_stroke = ifelse(prevalent_stroke == 1, "Yes", "No"),
         prevalent_hyp = ifelse(prevalent_hyp == 1, "Yes", "No"),
         diabetes = ifelse(diabetes == 1, "Yes", "No"))
```

```{r}
# density plots for continuous variables
heart_continuous = heart_eda %>%
  dplyr::select(age, cigs_per_day, tot_chol, sys_bp, dia_bp, bmi, heart_rate, 
                glucose, ten_year_chd)

heart_con_long = melt(heart_continuous, id.vars= "ten_year_chd") 

heart_con_long %>%
  ggplot(aes(x = value, color = ten_year_chd)) +
  geom_density() +
  labs(x = "Continuous variables", y = "Density") +
  facet_wrap(~variable, scales = "free", nrow = 2)
```

```{r warning = F}
# bar plots for categorical variables
heart_categorical = heart_eda %>%
  dplyr::select(male, education, current_smoker, bp_meds, prevalent_stroke, 
                prevalent_hyp, diabetes, ten_year_chd)

heart_cate_long = melt(heart_categorical, id.vars= "ten_year_chd") 

heart_cate_long %>%
  ggplot(aes(x = value, fill = ten_year_chd)) + 
  geom_bar(position = "fill") +
  labs(x = "Categorical variables", y = "Proportion") +
  facet_wrap(~variable, scales = "free", nrow = 2)
```

# Data partition
```{r}
indexTrain <- createDataPartition(y = heart$ten_year_chd, p = 0.75, list = FALSE)
heart_tr <- heart[indexTrain, ]
heart_te <- heart[-indexTrain, ]
# matrix of predictors 
x_tr <- model.matrix(ten_year_chd~., heart_tr)[,-1]
x_te <- model.matrix(ten_year_chd~., heart_te)[,-1]
# vector of response
y_tr <- heart_tr$ten_year_chd
y_te <- heart_te$ten_year_chd
```

## Model fitting
Training control.
```{r}
ctrl <- trainControl(method = "cv",
                     classProbs = TRUE, 
                     summaryFunction = twoClassSummary)
```

Logistic regression.
```{r}
set.seed(1)
model.glm <- train(x = x_tr,
                   y = y_tr,
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)
summary(model.glm)
```

Penalized logistic regression.

```{r}
glmnGrid <- expand.grid(.alpha = seq(0, 0.3, length = 16),
                        .lambda = exp(seq(-6, -2, length = 20)))
set.seed(1)
model.glmn <- train(x = x_tr,
                    y = y_tr,
                    method = "glmnet",
                    tuneGrid = glmnGrid,
                    metric = "ROC",
                    trControl = ctrl)

plot(model.glmn, xTrans = function(x) log(x))   
model.glmn$bestTune

summary(model.glmn)
```

GAM.

```{r}
set.seed(1)
model.gam <- train(x = x_tr,
                   y = y_tr,
                   method = "gam",
                   metric = "ROC",
                   trControl = ctrl)

#plot(model.gam$finalModel)
#model.gam$finalModel

summary(model.gam)
```

MARS.

```{r}
set.seed(1)
model.mars <- train(x = x_tr,
                    y = y_tr,
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:3, 
                                           nprune = 2:15),
                    metric = "ROC",
                    trControl = ctrl)

plot(model.mars)
model.mars$bestTune

coef(model.mars$finalModel) 
vip(model.mars$finalModel)

summary(model.mars)
```

KNN.

```{r, warning=FALSE}
set.seed(1)
model.knn <- train(x = x_tr,
                   y = y_tr,
                   method = "knn",
                   preProcess = c("center","scale"),
                   tuneGrid = data.frame(k = seq(1,200,by=5)),
                   trControl = ctrl)

ggplot(model.knn, highlight = TRUE)
model.knn$bestTune

summary(model.knn)
```


LDA.
```{r}
set.seed(1)
model.lda <- train(x = x_tr,
                   y = y_tr,
                   method = "lda",
                   metric = "ROC",
                   trControl = ctrl)

model.lda
```

QDA
```{r}
set.seed(1)
model.qda <- train(x = x_tr,
                   y = y_tr,
                   method = "qda",
                   metric = "ROC",
                   trControl = ctrl)

model.qda
```


Support vector classifier (linear kernel)
```{r}

# kernlab
set.seed(1)
svml.fit <- train(ten_year_chd ~ . , 
                  data = heart_tr, 
                  method = "svmLinear",
                  # preProcess = c("center", "scale"),
                  tuneGrid = data.frame(C = exp(seq(-2,5,len=20))),
                  trControl = ctrl)

plot(svml.fit, highlight = TRUE, xTrans = log)

# training error
confusionMatrix(svml.fit)
1-0.83

# test error
pred.linear.te <- predict(svml.fit, newdata = dat[-rowTrain,])
confusionMatrix(data = pred.linear.te, 
                reference = dat$purchase[-rowTrain])
1-0.8444
```

Classification tree

```{r}
set.seed(1)

rpart.fit2 = train(ten_year_chd ~ . ,
                   heart_tr,
                   method = "rpart",
                   tuneGrid = data.frame(cp = exp(seq(-10,-5, len = 80))),
                   trControl = ctrl,
                   metric = "ROC")

ggplot(rpart.fit2, highlight = TRUE)
rpart.plot(rpart.fit2$finalModel)

rpart.pred2 = predict(rpart.fit2, newdata = heart_te, type = "raw")
confusion_matrix = confusionMatrix(rpart.pred2, y_te) 
error_rate = 1 - confusion_matrix$overall[[1]]
error_rate
```

Test error rate is `r error_rate`. 

Random Forest

```{r}
rf.grid2 = expand.grid(mtry = 1:15, splitrule = "gini",
                       min.node.size = seq(from = 2, to = 10, by = 2))
set.seed(1)
rf.fit2 <- train(ten_year_chd ~ . ,
                 heart_tr,
                 method = "ranger", 
                 tuneGrid = rf.grid2, 
                 metric = "ROC", 
                 importance = "impurity",
                 trControl = ctrl)

ggplot(rf.fit2, highlight = TRUE)

plot(varImp(rf.fit2))

rf.pred2 = predict(rf.fit2, newdata = heart_te, type = "raw")
confusion_matrix2 = confusionMatrix(rf.pred2, y_te) 
error_rate2 = 1 - confusion_matrix2$overall[[1]]
error_rate2
```

Test error rate is `r error_rate2`. 

Boosting

```{r}
gbmA.grid <- expand.grid(n.trees = c(2000,3000,4000),
                         interaction.depth = 1:6,
                         shrinkage = c(0.001,0.003,0.005),
                         n.minobsinnode = 1)
set.seed(1)
gbmA.fit <- train(ten_year_chd ~ . , 
                  heart_tr, 
                  tuneGrid = gbmA.grid,
                  trControl = ctrl,
                  method = "gbm",
                  distribution = "adaboost",
                  metric = "ROC",
                  verbose = FALSE)

summary(gbmA.fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)

boost.pred2 = predict(gbmA.fit, newdata = heart_te, type = "raw")
confusion_matrix3 = confusionMatrix(boost.pred2, y_te) 
error_rate3 = 1 - confusion_matrix3$overall[[1]]
error_rate3
```

Test error rate is `r error_rate3`. 

Model Selection

```{r}
res <- resamples(list(GLM = model.glm, 
                      GLMNET = model.glmn, 
                      GAM = model.gam,
                      MARS = model.mars,
                      KNN = model.knn,
                      LDA = model.lda,
                      QDA = model.qda,
                      Classification_tree = rpart.fit2,
                      Random_forest = rf.fit2,
                      Boosting = gbmA.fit))
summary(res)

bwplot(res, metric = "ROC")
```


Now let's look at the test data performance.
```{r, warning=FALSE}
glm.pred <- predict(model.glm, newdata = x_te, type = "prob")[,2]
glmn.pred <- predict(model.glmn, newdata = x_te, type = "prob")[,2]
knn.pred <- predict(model.knn, newdata = x_te, type = "prob")[,2]
gam.pred <- predict(model.gam, newdata = x_te, type = "prob")[,2]
mars.pred <- predict(model.mars, newdata = x_te, type = "prob")[,2]
lda.pred <- predict(model.lda, newdata = x_te, type = "prob")[,2]
qda.pred <- predict(model.qda, newdata = x_te, type = "prob")[,2]


roc.glm <- roc(y_te, glm.pred)
roc.glmn <- roc(y_te, glmn.pred)
roc.knn <- roc(y_te, knn.pred)
roc.gam <- roc(y_te, gam.pred)
roc.mars <- roc(y_te, mars.pred)
roc.lda <- roc(y_te, lda.pred)
roc.qda <- roc(y_te, qda.pred)

auc <- c(roc.glm$auc[1], roc.glmn$auc[1], roc.knn$auc[1],
         roc.gam$auc[1], roc.mars$auc[1], roc.lda$auc[1],
         roc.qda$auc[1])

plot(roc.glm, legacy.axes = TRUE)
plot(roc.glmn, col = 2, add = TRUE)
plot(roc.knn, col = 3, add = TRUE)
plot(roc.gam, col = 4, add = TRUE)
plot(roc.mars, col = 5, add = TRUE)
plot(roc.lda, col = 6, add = TRUE)
plot(roc.qda, col = 7, add = TRUE)

modelNames <- c("glm","glmn","knn","gam","mars","lda","qda")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:7, lwd = 2)
```
